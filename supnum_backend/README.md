# Chatbot SupNum - RAG Implementation

## ğŸš€ Vue d'ensemble

Un systÃ¨me de chatbot intelligent basÃ© sur RAG (Retrieval-Augmented Generation) pour SupNum. Le systÃ¨me combine :
- **PostgreSQL** pour le stockage des documents et mÃ©tadonnÃ©es
- **Qdrant** pour la recherche vectorielle
- **Sentence Transformers** pour les embeddings
- **OpenAI/Claude** pour la gÃ©nÃ©ration de rÃ©ponses
- **FastAPI** pour l'API REST

## ğŸ“‹ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Question   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Query Handler      â”‚
â”‚  - Encode question   â”‚
â”‚  - Search Qdrant     â”‚
â”‚  - Generate answer   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                     â”‚
       v                     v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Qdrant     â”‚      â”‚  PostgreSQL  â”‚
â”‚  (Vectors)   â”‚      â”‚  (Metadata)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                     â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 v
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  LLM (GPT)   â”‚
          â”‚  - Context   â”‚
          â”‚  - Generate  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Installation

### 1. PrÃ©requis
- Python 3.11+
- Docker et Docker Compose
- Git

### 2. Cloner le projet
```bash
git clone <your-repo>
cd chatbot-supnum
```

### 3. Configuration
```bash
# Copier le fichier d'exemple
cp .env.example .env

# Ã‰diter .env avec vos clÃ©s API
nano .env
```

### 4. Lancer avec Docker
```bash
# DÃ©marrer tous les services
docker-compose up -d

# VÃ©rifier les logs
docker-compose logs -f app

# Initialiser la base de donnÃ©es
curl -X POST http://localhost:8000/init-db
```

### 5. Installation locale (sans Docker)
```bash
# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# Installer les dÃ©pendances
pip install -r requirements.txt

# DÃ©marrer PostgreSQL et Qdrant (via Docker)
docker-compose up -d postgres qdrant

# Lancer l'application
uvicorn app.main:app --reload
```

## ğŸ“š Utilisation de l'API

### 1. Indexer un document
```bash
curl -X POST "http://localhost:8000/documents" \
  -H "Content-Type: application/json" \
  -d '{
    "title": "Guide SupNum",
    "content": "SupNum est une Ã©cole spÃ©cialisÃ©e dans le numÃ©rique...",
    "source": "https://supnum.mr",
    "doc_type": "text"
  }'
```

### 2. Poser une question
```bash
curl -X POST "http://localhost:8000/ask" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Qu'\''est-ce que SupNum?",
    "top_k": 5,
    "score_threshold": 0.5,
    "use_context": true
  }'
```

### 3. Rechercher des chunks
```bash
curl -X POST "http://localhost:8000/search?query=formation&top_k=10"
```

### 4. Lister les documents
```bash
curl "http://localhost:8000/documents?limit=10"
```

### 5. Obtenir les statistiques
```bash
curl "http://localhost:8000/stats"
```

### 6. VÃ©rifier la santÃ© du systÃ¨me
```bash
curl "http://localhost:8000/health"
```

## ğŸ”§ Configuration avancÃ©e

### Chunking
Modifier dans `.env`:
```bash
CHUNK_SIZE=500          # Taille des chunks en caractÃ¨res
CHUNK_OVERLAP=50        # Chevauchement entre chunks
```

### ModÃ¨le d'embeddings
```bash
# all-MiniLM-L6-v2 (rapide, 384 dim)
EMBEDDING_MODEL=all-MiniLM-L6-v2
VECTOR_SIZE=384

# all-mpnet-base-v2 (meilleur, 768 dim)
EMBEDDING_MODEL=all-mpnet-base-v2
VECTOR_SIZE=768
```

### LLM Provider
**OpenAI:**
```bash
OPENAI_API_KEY=sk-...
LLM_MODEL=gpt-3.5-turbo
# ou
LLM_MODEL=gpt-4
```

**Anthropic Claude:**
```bash
ANTHROPIC_API_KEY=sk-ant-...
LLM_MODEL=claude-3-haiku-20240307
# ou
LLM_MODEL=claude-3-sonnet-20240229
```

## ğŸ“Š Structure du projet

```
chatbot-supnum/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ postgres.py          # Configuration PostgreSQL
â”‚   â”‚   â””â”€â”€ qdrant_client.py     # Client Qdrant
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ pg_models.py         # ModÃ¨les SQLAlchemy
â”‚   â”‚   â””â”€â”€ qdrant_models.py     # ModÃ¨les Pydantic
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ indexing.py          # Service d'indexation
â”‚   â”‚   â”œâ”€â”€ retrieval.py         # Service de rÃ©cupÃ©ration
â”‚   â”‚   â””â”€â”€ query_handler.py     # Gestionnaire de requÃªtes
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ chunking.py          # DÃ©coupage de texte
â”‚   â”‚   â”œâ”€â”€ embeddings.py        # GÃ©nÃ©ration d'embeddings
â”‚   â”‚   â””â”€â”€ logging.py           # Configuration des logs
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ api.py               # Routes API
â”‚   â””â”€â”€ main.py                  # Application principale
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md
```

## ğŸ§ª Tests

### Test manuel avec curl
```bash
# 1. Indexer un document de test
curl -X POST "http://localhost:8000/documents" \
  -H "Content-Type: application/json" \
  -d '{
    "title": "Test Document",
    "content": "Ceci est un document de test pour vÃ©rifier le systÃ¨me RAG.",
    "doc_type": "text"
  }'

# 2. Poser une question
curl -X POST "http://localhost:8000/ask" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Qu'\''est-ce qu'\''un document de test?",
    "top_k": 3
  }'
```

### Test avec Python
```python
import requests

# Indexer
response = requests.post(
    "http://localhost:8000/documents",
    json={
        "title": "Python Test",
        "content": "Test content...",
        "doc_type": "text"
    }
)
print(response.json())

# Poser une question
response = requests.post(
    "http://localhost:8000/ask",
    json={"question": "Test question?"}
)
print(response.json())
```

## ğŸ” Monitoring

### Logs
```bash
# Logs de l'application
docker-compose logs -f app

# Logs Postgres
docker-compose logs -f postgres

# Logs Qdrant
docker-compose logs -f qdrant
```

### Interface Qdrant
AccÃ©der Ã  l'interface web: http://localhost:6333/dashboard

## ğŸš¨ DÃ©pannage

### ProblÃ¨me: "Connection refused" Ã  Postgres
```bash
# VÃ©rifier que Postgres est dÃ©marrÃ©
docker-compose ps

# RedÃ©marrer Postgres
docker-compose restart postgres
```

### ProblÃ¨me: Qdrant ne rÃ©pond pas
```bash
# VÃ©rifier la santÃ© de Qdrant
curl http://localhost:6333/health

# RecrÃ©er le conteneur
docker-compose down qdrant
docker-compose up -d qdrant
```

### ProblÃ¨me: Embeddings trop lents
- Utiliser un modÃ¨le plus petit (all-MiniLM-L6-v2)
- Augmenter le batch_size dans embeddings.py
- Utiliser un GPU si disponible

### ProblÃ¨me: RÃ©ponses non pertinentes
- RÃ©duire score_threshold (ex: 0.3)
- Augmenter top_k (ex: 10)
- Activer use_context=true
- AmÃ©liorer le chunking (taille et overlap)

## ğŸ“ˆ Performance

### Benchmarks typiques
- Indexation: ~2-5 docs/sec
- RequÃªte (retrieval): ~50-100ms
- GÃ©nÃ©ration (LLM): ~1-3s
- Total end-to-end: ~1.5-3.5s

### Optimisation
1. **Cache les embeddings** pour les requÃªtes frÃ©quentes
2. **Batch processing** pour l'indexation massive
3. **Connection pooling** pour PostgreSQL
4. **GPU** pour les embeddings si disponible

## ğŸ” SÃ©curitÃ©

- Ne jamais commiter le fichier `.env`
- Utiliser des secrets management en production
- Limiter l'accÃ¨s API avec authentification
- Valider tous les inputs utilisateur
- Rate limiting sur les endpoints

## ğŸ“ TODO

- [ ] Ajouter l'authentification JWT
- [ ] ImplÃ©menter le rate limiting
- [ ] Ajouter des tests unitaires
- [ ] Support pour PDF et documents Office
- [ ] Interface web React/Vue
- [ ] Cache Redis pour les requÃªtes
- [ ] Monitoring avec Prometheus
- [ ] CI/CD avec GitHub Actions

## ğŸ“„ Licence

MIT

## ğŸ‘¥ Contact

Pour toute question: contact@supnum.mr
